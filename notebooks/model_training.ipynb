{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Car Detection - Model Training with YOLOv8\n",
                "\n",
                "This notebook guides you through the process of training a YOLOv8 model for car detection using the dataset prepared with Roboflow."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Install Required Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install ultralytics matplotlib tensorflow"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Import Required Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import yaml\n",
                "from ultralytics import YOLO\n",
                "import matplotlib.pyplot as plt\n",
                "from IPython.display import Image, display"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Define Dataset Path\n",
                "\n",
                "Point to the dataset we prepared in the previous notebook."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Update this path to point to your dataset location\n",
                "data_path = \"../data/vehicles-detection-v1\"\n",
                "\n",
                "# Verify the data.yaml file exists\n",
                "yaml_path = os.path.join(data_path, \"data.yaml\")\n",
                "assert os.path.exists(yaml_path), f\"data.yaml not found at {yaml_path}\"\n",
                "\n",
                "# Load and display dataset configuration\n",
                "with open(yaml_path, \"r\") as f:\n",
                "    data_config = yaml.safe_load(f)\n",
                "\n",
                "print(\"Dataset configuration:\")\n",
                "for key, value in data_config.items():\n",
                "    print(f\"  {key}: {value}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Initialize YOLO Model\n",
                "\n",
                "We'll start with a pre-trained YOLOv8 model and fine-tune it for car detection."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Choose model size based on your requirements and computational resources\n",
                "# Options: 'yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt', 'yolov8l.pt', 'yolov8x.pt'\n",
                "model = YOLO('yolov8s.pt')  # We'll use the small model for training speed\n",
                "\n",
                "print(f\"Model loaded: {model.type}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model Training\n",
                "\n",
                "Now we'll train the model on our car detection dataset. We'll define various hyperparameters for the training process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define training hyperparameters\n",
                "# These can be adjusted based on your dataset and computational resources\n",
                "epochs = 50\n",
                "batch_size = 16\n",
                "imgsz = 640  # Image size\n",
                "\n",
                "# Start training\n",
                "results = model.train(\n",
                "    data=yaml_path,\n",
                "    epochs=epochs,\n",
                "    batch=batch_size,\n",
                "    imgsz=imgsz,\n",
                "    patience=10,  # Early stopping patience\n",
                "    save=True,  # Save best model\n",
                "    device='0',  # GPU device (use 'cpu' if no GPU available)\n",
                "    project=\"../models\",\n",
                "    name=\"car_detection_model\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Evaluate the Model\n",
                "\n",
                "After training, let's evaluate the model's performance on the validation set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Path to the best trained model\n",
                "best_model_path = \"../models/car_detection_model/weights/best.pt\"\n",
                "\n",
                "# Load the model\n",
                "trained_model = YOLO(best_model_path)\n",
                "\n",
                "# Run validation\n",
                "val_results = trained_model.val(data=yaml_path)\n",
                "\n",
                "print(f\"Validation mAP50: {val_results.box.map50:.4f}\")\n",
                "print(f\"Validation mAP50-95: {val_results.box.map:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Visualize Training Metrics\n",
                "\n",
                "Let's visualize the training results to understand how our model improved over time."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display training results plots\n",
                "plots_path = os.path.join(\"../models/car_detection_model\", \"results.png\")\n",
                "\n",
                "if os.path.exists(plots_path):\n",
                "    display(Image(filename=plots_path))\n",
                "else:\n",
                "    print(f\"Training results plot not found at {plots_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Run Inference on Sample Images\n",
                "\n",
                "Let's test our trained model on some sample validation images."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get a few sample images from the validation set\n",
                "val_images_dir = os.path.join(data_path, \"valid/images\")\n",
                "val_images = [os.path.join(val_images_dir, f) for f in os.listdir(val_images_dir)][:5]\n",
                "\n",
                "# Run inference on sample images\n",
                "for img_path in val_images:\n",
                "    # Run prediction\n",
                "    results = trained_model(img_path)\n",
                "    \n",
                "    # Get the result object\n",
                "    result = results[0]\n",
                "    \n",
                "    # Plot results\n",
                "    fig, ax = plt.subplots(figsize=(12, 9))\n",
                "    ax.imshow(result.plot()[:, :, ::-1])  # Convert BGR to RGB\n",
                "    plt.axis('off')\n",
                "    plt.title(f\"Predictions on {os.path.basename(img_path)}\")\n",
                "    plt.show()\n",
                "    \n",
                "    # Print detection counts\n",
                "    boxes = result.boxes\n",
                "    print(f\"Image: {os.path.basename(img_path)}\")\n",
                "    print(f\"  Detections: {len(boxes)}\")\n",
                "    \n",
                "    if len(boxes) > 0:\n",
                "        # Print confidence scores\n",
                "        confidences = boxes.conf.tolist()\n",
                "        classes = boxes.cls.tolist()\n",
                "        class_names = [data_config['names'][int(c)] for c in classes]\n",
                "        \n",
                "        for i, (conf, cls_name) in enumerate(zip(confidences, class_names)):\n",
                "            print(f\"    {i+1}. {cls_name}: {conf:.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Apply Post-processing Image Techniques\n",
                "\n",
                "Let's explore some post-processing techniques to improve detection visualization."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import cv2\n",
                "import numpy as np\n",
                "import torch\n",
                "\n",
                "def apply_post_processing(image_path, model, conf_threshold=0.25, iou_threshold=0.45):\n",
                "    # Load image\n",
                "    img = cv2.imread(image_path)\n",
                "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "    \n",
                "    # Run prediction\n",
                "    results = model(img_rgb, conf=conf_threshold, iou=iou_threshold)\n",
                "    result = results[0]\n",
                "    \n",
                "    # Get detections\n",
                "    boxes = result.boxes\n",
                "    \n",
                "    # Original detection\n",
                "    original_plot = result.plot()\n",
                "    original_plot_rgb = cv2.cvtColor(original_plot, cv2.COLOR_BGR2RGB)\n",
                "    \n",
                "    # Heat map visualization\n",
                "    heatmap = np.zeros((img.shape[0], img.shape[1]), dtype=np.float32)\n",
                "    \n",
                "    if len(boxes) > 0:\n",
                "        for box, conf in zip(boxes.xyxy, boxes.conf):\n",
                "            x1, y1, x2, y2 = map(int, box)\n",
                "            conf_value = float(conf)\n",
                "            cv2.rectangle(heatmap, (x1, y1), (x2, y2), conf_value, -1)\n",
                "    \n",
                "    heatmap = cv2.normalize(heatmap, None, 0, 255, cv2.NORM_MINMAX)\n",
                "    heatmap = np.uint8(heatmap)\n",
                "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
                "    \n",
                "    # Blend original image with heatmap\n",
                "    heatmap_overlay = cv2.addWeighted(img, 0.7, heatmap, 0.3, 0)\n",
                "    heatmap_overlay_rgb = cv2.cvtColor(heatmap_overlay, cv2.COLOR_BGR2RGB)\n",
                "    \n",
                "    # Visualization with blur background\n",
                "    blurred_bg = cv2.GaussianBlur(img, (21, 21), 0)\n",
                "    mask = np.zeros_like(img)\n",
                "    \n",
                "    if len(boxes) > 0:\n",
                "        for box in boxes.xyxy:\n",
                "            x1, y1, x2, y2 = map(int, box)\n",
                "            # Create mask for the detection region\n",
                "            mask[y1:y2, x1:x2] = 255\n",
                "    \n",
                "    # Create focused image: blurred background with sharp detections\n",
                "    focused_img = np.where(mask > 0, img, blurred_bg)\n",
                "    focused_img_rgb = cv2.cvtColor(focused_img, cv2.COLOR_BGR2RGB)\n",
                "    \n",
                "    # Display results\n",
                "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
                "    \n",
                "    axes[0, 0].imshow(img_rgb)\n",
                "    axes[0, 0].set_title(\"Original Image\")\n",
                "    axes[0, 0].axis('off')\n",
                "    \n",
                "    axes[0, 1].imshow(original_plot_rgb)\n",
                "    axes[0, 1].set_title(\"YOLO Detection\")\n",
                "    axes[0, 1].axis('off')\n",
                "    \n",
                "    axes[1, 0].imshow(heatmap_overlay_rgb)\n",
                "    axes[1, 0].set_title(\"Confidence Heatmap Overlay\")\n",
                "    axes[1, 0].axis('off')\n",
                "    \n",
                "    axes[1, 1].imshow(focused_img_rgb)\n",
                "    axes[1, 1].set_title(\"Focus Effect (Blur Background)\")\n",
                "    axes[1, 1].axis('off')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "# Apply post-processing to one sample image\n",
                "if val_images:\n",
                "    apply_post_processing(val_images[0], trained_model)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Export the Model for Inference\n",
                "\n",
                "Finally, let's export our trained model in different formats for deployment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Export the model to ONNX format\n",
                "trained_model.export(format=\"onnx\")\n",
                "\n",
                "# Export to other formats if needed\n",
                "# trained_model.export(format=\"tflite\")\n",
                "# trained_model.export(format=\"torchscript\")\n",
                "\n",
                "print(\"Model exported successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Save Model to Project Models Directory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import shutil\n",
                "\n",
                "# Source and destination paths\n",
                "src_model_path = best_model_path\n",
                "dst_model_path = \"../models/best_car_detection.pt\"\n",
                "\n",
                "# Copy the best model\n",
                "shutil.copy(src_model_path, dst_model_path)\n",
                "print(f\"Best model saved to {dst_model_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Next Steps\n",
                "\n",
                "Now that you have trained a car detection model, you can use it for inference on new images and videos. See the `../src/detect.py` script for inference implementation."
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}